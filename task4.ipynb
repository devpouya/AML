{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_eeg1path = \"train_eeg1.csv\"\n",
    "train_eeg2path = \"train_eeg2.csv\"\n",
    "train_emgpath = \"train_emg.csv\"\n",
    "\n",
    "\n",
    "\n",
    "label_path = \"train_labels.csv\"\n",
    "\n",
    "\n",
    "test_eeg1path = \"test_eeg1.csv\"\n",
    "\n",
    "test_eeg2path = \"test_eeg2.csv\"\n",
    "test_emgpath = \"test_emg.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample_path = \"sample.csv\"\n",
    "\n",
    "df_eeg1 = pd.read_csv(train_eeg1path)\n",
    "df_eeg2 = pd.read_csv(train_eeg2path)\n",
    "df_emg = pd.read_csv(train_emgpath)\n",
    "\n",
    "\n",
    "\n",
    "labeldf = pd.read_csv(label_path)\n",
    "\n",
    "test_eeg1 = pd.read_csv(test_eeg1path)\n",
    "test_eeg2 = pd.read_csv(test_eeg2path)\n",
    "test_emg = pd.read_csv(test_emgpath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labels = labeldf.values\n",
    "labels = labels[:,1]\n",
    "\n",
    "\n",
    "eeg1_data = df_eeg1.values\n",
    "eeg2_data = df_eeg2.values\n",
    "emg_data = df_emg.values\n",
    "\n",
    "eeg1_test = test_eeg1.values\n",
    "eeg2_test = test_eeg2.values\n",
    "emg_test = test_emg.values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eeg1_data = eeg1_data[:,1:]\n",
    "eeg2_data = eeg2_data[:,1:]\n",
    "emg_data = emg_data[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eeg1_test = eeg1_test[:,1:]\n",
    "eeg2_test = eeg2_test[:,1:]\n",
    "emg_test = emg_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64800, 512)\n",
      "(64800, 512)\n",
      "(64800, 512)\n"
     ]
    }
   ],
   "source": [
    "print(eeg1_data.shape)\n",
    "print(eeg2_data.shape)\n",
    "print(emg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43200, 512)\n"
     ]
    }
   ],
   "source": [
    "print(eeg1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 34114, 2: 27133, 3: 3553}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 34114, 2: 27133, 3: 3553}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def class_counts(lables):\n",
    "    unique, counts = np.unique(labels,return_counts=True)\n",
    "    class_counts = dict(zip(unique,counts))\n",
    "    print(class_counts)\n",
    "    return class_counts\n",
    "\n",
    "class_counts(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(y_true, y_pred,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biosppy.signals.eeg import _power_features\n",
    "from biosppy.signals.emg import emg\n",
    "from biosppy.signals import tools as st\n",
    "import biosppy.utils as utils\n",
    "\n",
    "def filter_signal(signal):\n",
    "    b, a = st.get_filter(ftype='butter',\n",
    "                         band='highpass',\n",
    "                         order=8,\n",
    "                         frequency=4,\n",
    "                         sampling_rate=128)\n",
    "\n",
    "    aux, _ = st._filter_signal(b, a, signal=signal, check_phase=True, axis=0)\n",
    "\n",
    "    # low pass filter\n",
    "    b, a = st.get_filter(ftype='butter',\n",
    "                         band='lowpass',\n",
    "                         order=16,\n",
    "                         frequency=40,\n",
    "                         sampling_rate=128)\n",
    "\n",
    "    filtered, _ = st._filter_signal(b, a, signal=aux, check_phase=True, axis=0)\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def power_features(signal=None,\n",
    "                       sampling_rate=1000.,\n",
    "                       size=0.25,\n",
    "                       overlap=0.5,\n",
    "                       bands=[[4, 8], [8, 10], [10, 13], [13, 25], [25, 40]],\n",
    "                       custom=False):\n",
    "    \"\"\"Extract band power features from EEG signals.\n",
    "\n",
    "    Computes the average signal power, with overlapping windows, in typical\n",
    "    EEG frequency bands:\n",
    "    * Theta: from 4 to 8 Hz,\n",
    "    * Lower Alpha: from 8 to 10 Hz,\n",
    "    * Higher Alpha: from 10 to 13 Hz,\n",
    "    * Beta: from 13 to 25 Hz,\n",
    "    * Gamma: from 25 to 40 Hz.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal  array\n",
    "        Filtered EEG signal matrix; each column is one EEG channel.\n",
    "    sampling_rate : int, float, optional\n",
    "        Sampling frequency (Hz).\n",
    "    size : float, optional\n",
    "        Window size (seconds).\n",
    "    overlap : float, optional\n",
    "        Window overlap (0 to 1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ts : array\n",
    "        Features time axis reference (seconds).\n",
    "    theta : array\n",
    "        Average power in the 4 to 8 Hz frequency band; each column is one EEG\n",
    "        channel.\n",
    "    alpha_low : array\n",
    "        Average power in the 8 to 10 Hz frequency band; each column is one EEG\n",
    "        channel.\n",
    "    alpha_high : array\n",
    "        Average power in the 10 to 13 Hz frequency band; each column is one EEG\n",
    "        channel.\n",
    "    beta : array\n",
    "        Average power in the 13 to 25 Hz frequency band; each column is one EEG\n",
    "        channel.\n",
    "    gamma : array\n",
    "        Average power in the 25 to 40 Hz frequency band; each column is one EEG\n",
    "        channel.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # check inputs\n",
    "    if signal is None:\n",
    "        raise TypeError(\"Please specify an input signal.\")\n",
    "\n",
    "    # ensure numpy\n",
    "    signal = np.array(signal)\n",
    "    nch = signal.shape[1]\n",
    "    \n",
    "    # this line is new\n",
    "    signal = filter_signal(signal)\n",
    "\n",
    "    sampling_rate = float(sampling_rate)\n",
    "\n",
    "    # convert sizes to samples\n",
    "    size = int(size * sampling_rate)\n",
    "    step = size - int(overlap * size)\n",
    "\n",
    "    # padding\n",
    "    min_pad = 1024\n",
    "    pad = None\n",
    "    if size < min_pad:\n",
    "        pad = min_pad - size\n",
    "\n",
    "    # frequency bands\n",
    "    # bands = [[4, 8], [8, 10], [10, 13], [13, 25], [25, 40]]\n",
    "    nb = len(bands)\n",
    "\n",
    "    # windower\n",
    "    fcn_kwargs = {'sampling_rate': sampling_rate, 'bands': bands, 'pad': pad}\n",
    "    index, values = st.windower(signal=signal,\n",
    "                                size=size,\n",
    "                                step=step,\n",
    "                                kernel='hann',\n",
    "                                fcn=_power_features,\n",
    "                                fcn_kwargs=fcn_kwargs)\n",
    "\n",
    "    # median filter\n",
    "    md_size = int(0.625 * sampling_rate / float(step))\n",
    "    if md_size % 2 == 0:\n",
    "        # must be odd\n",
    "        md_size += 1\n",
    "\n",
    "    for i in range(nb):\n",
    "        for j in range(nch):\n",
    "            values[:, i, j], _ = st.smoother(signal=values[:, i, j],\n",
    "                                             kernel='median',\n",
    "                                             size=md_size)\n",
    "\n",
    "    # extract individual bands\n",
    "    theta = values[:, 0, :]\n",
    "    alpha_low = values[:, 1, :]\n",
    "    alpha_high = values[:, 2, :]\n",
    "    beta = values[:, 3, :]\n",
    "    gamma = values[:, 4, :]\n",
    "    \n",
    "    delta = values[:,0,:]\n",
    "    theta = values[:,1,:]\n",
    "    alpha = values[:,2,:]\n",
    "    spindle = values[:,3,:]\n",
    "    beta1 = values[:,4,:]\n",
    "    beta2 = values[:,5,:]\n",
    "    # convert indices to seconds\n",
    "    ts = index.astype('float') / sampling_rate\n",
    "\n",
    "    # output\n",
    "    args = (ts, theta, alpha_low, alpha_high, beta, gamma)\n",
    "    args2 = (ts, delta, theta, alpha, spindle, beta1, beta2)\n",
    "    \n",
    "    names = ('ts', 'theta', 'alpha_low', 'alpha_high', 'beta', 'gamma')\n",
    "    names2 = (\"ts\", \"delta\", \"theta\", \"alpha\", \"spindle\", \"beta1\", \"beta2\")\n",
    "    if custom:\n",
    "        return utils.ReturnTuple(args2, names2)\n",
    "    else:\n",
    "        return utils.ReturnTuple(args, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bands = [[0.39, 3.13], [3.13,8.46], [8.46,10.93],[10.93,15.63],[15.63,21.88],[21.88,37.50]]\n",
    "\"\"\"\n",
    "#for i in range(eeg1_data.shape[0]):\n",
    "    signal = eeg1_data[i,:].reshape(1,eeg1_data.shape[1])\n",
    "    vals = power_features(signal=signal,sampling_rate=128,bands = bands, custom = True)\n",
    "    delta = vals[\"delta\"]\n",
    "    theta = vals[\"theta\"]\n",
    "    alpha = vals[\"alpha\"]\n",
    "    spindle = vals[\"spindle\"]\n",
    "    beta1 = vals[\"beta1\"]\n",
    "    beta2 = vals[\"beta2\"]\n",
    "    print(delta.shape)\n",
    "    print(theta.shape)\n",
    "    print(alpha.shape)\n",
    "    print(spindle.shape)\n",
    "    print(beta1.shape)\n",
    "    print(beta2.shape)\n",
    "\"\"\"\n",
    "vals = power_features(signal=eeg1_data,sampling_rate=128,bands = bands, custom = True)\n",
    "\n",
    "#vals1 = get_power_features(eeg1_data,sampling_rate=128)\n",
    "#vals2 = get_power_features(eeg2_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = v[\"delta\"]\n",
    "print(delta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4049, 512)\n",
      "(4049, 512)\n",
      "(4049, 512)\n",
      "(4049, 512)\n",
      "(4049, 512)\n",
      "(4049, 512)\n"
     ]
    }
   ],
   "source": [
    "delta = vals[\"delta\"]\n",
    "theta = vals[\"theta\"]\n",
    "alpha = vals[\"alpha\"]\n",
    "spindle = vals[\"spindle\"]\n",
    "beta1 = vals[\"beta1\"]\n",
    "bdeeta2 = vals[\"beta2\"]\n",
    "print(delta.shape)\n",
    "print(theta.shape)\n",
    "print(alpha.shape)\n",
    "print(spindle.shape)\n",
    "print(beta1.shape)\n",
    "print(beta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy(E):\n",
    "    p = np.power(E,2)\n",
    "    p = np.sum(p,axis=1)\n",
    "    return np.sqrt(p)\n",
    "\n",
    "def signal_stats(signal):\n",
    " \n",
    "    # mean\n",
    "    mean = np.mean(signal,axis=1)\n",
    "\n",
    "    # median\n",
    "    median = np.median(signal,axis=1)\n",
    "\n",
    "    # maximum amplitude abs\n",
    "    #maxAmpAbs = np.abs(signal - mean).max()\n",
    "\n",
    "    # minimum amplitude abs\n",
    "    #minAmpAbs = np.abs(signal - mean).min()\n",
    "\n",
    "    # maximum amplitude\n",
    "    #maxAmp = (signal - mean).max()\n",
    "\n",
    "    # minimum amplitude\n",
    "    #minAmp = (signal - mean).min()\n",
    "\n",
    "    # variance\n",
    "    sigma2 = np.var(signal,axis=1)\n",
    "\n",
    "    # standard deviation\n",
    "    sigma = np.std(signal,axis=1)\n",
    "\n",
    "    # absolute deviation\n",
    "    #ad = np.sum(np.abs(signal - median))\n",
    "\n",
    "    # kurtosis\n",
    "    #kurt = stats.kurtosis(signal, bias=False)\n",
    "\n",
    "    # skweness\n",
    "    #skew = stats.skew(signal, bias=False)\n",
    "        \n",
    "        \n",
    "    return mean, median, sigma2, sigma\n",
    "\n",
    "def eeg_features_(delta, theta, alpha, spindle, beta1, beta2):\n",
    "    delta = vals[\"delta\"]\n",
    "    theta = vals[\"theta\"]\n",
    "    alpha = vals[\"alpha\"]\n",
    "    spindle = vals[\"spindle\"]\n",
    "    beta1 = vals[\"beta1\"]\n",
    "    beta2 = vals[\"beta2\"]\n",
    "    e1 = energy(delta)\n",
    "    e2 = energy(theta)\n",
    "    e3 = energy(alpha)\n",
    "    e4 = energy(spindle)\n",
    "    e5 = energy(beta1)\n",
    "    e6 = energy(beta2)\n",
    "    \n",
    "    total_energy = e1+e2+e3+e4+e5+e6\n",
    "    \n",
    "    ratio1 = e3/(e1+e2)\n",
    "    ratio2 = e1/(e2+e3)\n",
    "    ratio3 = e2/(e3+e1)\n",
    "    \n",
    "    ratio4 = e1/(e5+e4)\n",
    "    ratio5 = e2/(e4+e3)\n",
    "    \n",
    "    (theta_mean,theta_median,theta_sigma2,theta_sigma) = signal_stats(theta)\n",
    "    (alphal_mean,alphal_median,alphal_sigma2,alphal_sigma) = signal_stats(delta)\n",
    "    (alphah_mean,alphah_median,alphah_sigma2,alphah_sigma) = signal_stats(alpha)\n",
    "    (beta_mean,beta_median,beta_sigma2,beta_sigma) = signal_stats(spindle)\n",
    "    (gamma_mean,gamma_median,gamma_sigma2,gamma_sigma) = signal_stats(beta1)\n",
    "    (beta2_mean,beta2_median,beta2_sigma2,beta2_sigma) = signal_stats(beta2)\n",
    "\n",
    "\n",
    "\n",
    "    features = np.zeros((1,theta.shape[0]))\n",
    "    \n",
    "    features = np.hstack((e1,e2,e3,e4,e5,total_energy,ratio1,ratio2,ratio3,ratio4,ratio5,theta_mean,\n",
    "                   theta_median,theta_sigma2,theta_sigma,alphal_mean,alphal_median,alphal_sigma2,\n",
    "                   alphal_sigma, alphah_mean, alphah_median, alphah_sigma2, alphah_sigma,\n",
    "                   beta_mean, beta_median, beta_sigma2, beta_sigma, gamma_mean, gamma_median,\n",
    "                   gamma_sigma2, gamma_sigma,beta2_mean,beta2_median,beta2_sigma2,beta2_sigma))\n",
    "    #features = features.reshape((features.shape[1],features.shape[0]))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def eeg_features(vals):\n",
    "    delta = vals[\"delta\"]\n",
    "    theta = vals[\"theta\"]\n",
    "    alpha = vals[\"alpha\"]\n",
    "    spindle = vals[\"spindle\"]\n",
    "    beta1 = vals[\"beta1\"]\n",
    "    beta2 = vals[\"beta2\"]\n",
    "    f1 = eeg_features_(delta[:,0],theta[:,0],alpha[:,0],spindle[:,0],beta1[:,0],beta2[:,0])\n",
    "    f2 = eeg_features_(delta[:,1],theta[:,1],alpha[:,1],spindle[:,1],beta1[:,1],beta2[:,1])\n",
    "    f1 = f1.reshape(1,f1.shape[0])\n",
    "    f2 = f2.reshape(1,f2.shape[0])\n",
    "    f = np.concatenate((f1,f2),axis=1)\n",
    "    return f\n",
    "#features1 = eeg_features(theta1,alpha_low1,alpha_high1,beta1,gamma1)\n",
    "#features2 = eeg_features(theta2,alpha_low2,alpha_high2,beta2,gamma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING ROW 0 PLEASE WAIT\n",
      "EVALUATING ROW 300 PLEASE WAIT\n",
      "EVALUATING ROW 600 PLEASE WAIT\n",
      "EVALUATING ROW 900 PLEASE WAIT\n",
      "EVALUATING ROW 1200 PLEASE WAIT\n",
      "EVALUATING ROW 1500 PLEASE WAIT\n",
      "EVALUATING ROW 1800 PLEASE WAIT\n",
      "EVALUATING ROW 2100 PLEASE WAIT\n",
      "EVALUATING ROW 2400 PLEASE WAIT\n",
      "EVALUATING ROW 2700 PLEASE WAIT\n",
      "EVALUATING ROW 3000 PLEASE WAIT\n",
      "EVALUATING ROW 3300 PLEASE WAIT\n",
      "EVALUATING ROW 3600 PLEASE WAIT\n",
      "EVALUATING ROW 3900 PLEASE WAIT\n",
      "EVALUATING ROW 4200 PLEASE WAIT\n",
      "EVALUATING ROW 4500 PLEASE WAIT\n",
      "EVALUATING ROW 4800 PLEASE WAIT\n",
      "EVALUATING ROW 5100 PLEASE WAIT\n",
      "EVALUATING ROW 5400 PLEASE WAIT\n",
      "EVALUATING ROW 5700 PLEASE WAIT\n",
      "EVALUATING ROW 6000 PLEASE WAIT\n",
      "EVALUATING ROW 6300 PLEASE WAIT\n",
      "EVALUATING ROW 6600 PLEASE WAIT\n",
      "EVALUATING ROW 6900 PLEASE WAIT\n",
      "EVALUATING ROW 7200 PLEASE WAIT\n",
      "EVALUATING ROW 7500 PLEASE WAIT\n",
      "EVALUATING ROW 7800 PLEASE WAIT\n",
      "EVALUATING ROW 8100 PLEASE WAIT\n",
      "EVALUATING ROW 8400 PLEASE WAIT\n",
      "EVALUATING ROW 8700 PLEASE WAIT\n",
      "EVALUATING ROW 9000 PLEASE WAIT\n",
      "EVALUATING ROW 9300 PLEASE WAIT\n",
      "EVALUATING ROW 9600 PLEASE WAIT\n",
      "EVALUATING ROW 9900 PLEASE WAIT\n",
      "EVALUATING ROW 10200 PLEASE WAIT\n",
      "EVALUATING ROW 10500 PLEASE WAIT\n",
      "EVALUATING ROW 10800 PLEASE WAIT\n",
      "EVALUATING ROW 11100 PLEASE WAIT\n",
      "EVALUATING ROW 11400 PLEASE WAIT\n",
      "EVALUATING ROW 11700 PLEASE WAIT\n",
      "EVALUATING ROW 12000 PLEASE WAIT\n",
      "EVALUATING ROW 12300 PLEASE WAIT\n",
      "EVALUATING ROW 12600 PLEASE WAIT\n",
      "EVALUATING ROW 12900 PLEASE WAIT\n",
      "EVALUATING ROW 13200 PLEASE WAIT\n",
      "EVALUATING ROW 13500 PLEASE WAIT\n",
      "EVALUATING ROW 13800 PLEASE WAIT\n",
      "EVALUATING ROW 14100 PLEASE WAIT\n",
      "EVALUATING ROW 14400 PLEASE WAIT\n",
      "EVALUATING ROW 14700 PLEASE WAIT\n",
      "EVALUATING ROW 15000 PLEASE WAIT\n",
      "EVALUATING ROW 15300 PLEASE WAIT\n",
      "EVALUATING ROW 15600 PLEASE WAIT\n",
      "EVALUATING ROW 15900 PLEASE WAIT\n",
      "EVALUATING ROW 16200 PLEASE WAIT\n",
      "EVALUATING ROW 16500 PLEASE WAIT\n",
      "EVALUATING ROW 16800 PLEASE WAIT\n",
      "EVALUATING ROW 17100 PLEASE WAIT\n",
      "EVALUATING ROW 17400 PLEASE WAIT\n",
      "EVALUATING ROW 17700 PLEASE WAIT\n",
      "EVALUATING ROW 18000 PLEASE WAIT\n",
      "EVALUATING ROW 18300 PLEASE WAIT\n",
      "EVALUATING ROW 18600 PLEASE WAIT\n",
      "EVALUATING ROW 18900 PLEASE WAIT\n",
      "EVALUATING ROW 19200 PLEASE WAIT\n",
      "EVALUATING ROW 19500 PLEASE WAIT\n",
      "EVALUATING ROW 19800 PLEASE WAIT\n",
      "EVALUATING ROW 20100 PLEASE WAIT\n",
      "EVALUATING ROW 20400 PLEASE WAIT\n",
      "EVALUATING ROW 20700 PLEASE WAIT\n",
      "EVALUATING ROW 21000 PLEASE WAIT\n",
      "EVALUATING ROW 21300 PLEASE WAIT\n",
      "EVALUATING ROW 21600 PLEASE WAIT\n",
      "EVALUATING ROW 21900 PLEASE WAIT\n",
      "EVALUATING ROW 22200 PLEASE WAIT\n",
      "EVALUATING ROW 22500 PLEASE WAIT\n",
      "EVALUATING ROW 22800 PLEASE WAIT\n",
      "EVALUATING ROW 23100 PLEASE WAIT\n",
      "EVALUATING ROW 23400 PLEASE WAIT\n",
      "EVALUATING ROW 23700 PLEASE WAIT\n",
      "EVALUATING ROW 24000 PLEASE WAIT\n",
      "EVALUATING ROW 24300 PLEASE WAIT\n",
      "EVALUATING ROW 24600 PLEASE WAIT\n",
      "EVALUATING ROW 24900 PLEASE WAIT\n",
      "EVALUATING ROW 25200 PLEASE WAIT\n",
      "EVALUATING ROW 25500 PLEASE WAIT\n",
      "EVALUATING ROW 25800 PLEASE WAIT\n",
      "EVALUATING ROW 26100 PLEASE WAIT\n",
      "EVALUATING ROW 26400 PLEASE WAIT\n",
      "EVALUATING ROW 26700 PLEASE WAIT\n",
      "EVALUATING ROW 27000 PLEASE WAIT\n",
      "EVALUATING ROW 27300 PLEASE WAIT\n",
      "EVALUATING ROW 27600 PLEASE WAIT\n",
      "EVALUATING ROW 27900 PLEASE WAIT\n",
      "EVALUATING ROW 28200 PLEASE WAIT\n",
      "EVALUATING ROW 28500 PLEASE WAIT\n",
      "EVALUATING ROW 28800 PLEASE WAIT\n",
      "EVALUATING ROW 29100 PLEASE WAIT\n",
      "EVALUATING ROW 29400 PLEASE WAIT\n",
      "EVALUATING ROW 29700 PLEASE WAIT\n",
      "EVALUATING ROW 30000 PLEASE WAIT\n",
      "EVALUATING ROW 30300 PLEASE WAIT\n",
      "EVALUATING ROW 30600 PLEASE WAIT\n",
      "EVALUATING ROW 30900 PLEASE WAIT\n",
      "EVALUATING ROW 31200 PLEASE WAIT\n",
      "EVALUATING ROW 31500 PLEASE WAIT\n",
      "EVALUATING ROW 31800 PLEASE WAIT\n",
      "EVALUATING ROW 32100 PLEASE WAIT\n",
      "EVALUATING ROW 32400 PLEASE WAIT\n",
      "EVALUATING ROW 32700 PLEASE WAIT\n",
      "EVALUATING ROW 33000 PLEASE WAIT\n",
      "EVALUATING ROW 33300 PLEASE WAIT\n",
      "EVALUATING ROW 33600 PLEASE WAIT\n",
      "EVALUATING ROW 33900 PLEASE WAIT\n",
      "EVALUATING ROW 34200 PLEASE WAIT\n",
      "EVALUATING ROW 34500 PLEASE WAIT\n",
      "EVALUATING ROW 34800 PLEASE WAIT\n",
      "EVALUATING ROW 35100 PLEASE WAIT\n",
      "EVALUATING ROW 35400 PLEASE WAIT\n",
      "EVALUATING ROW 35700 PLEASE WAIT\n",
      "EVALUATING ROW 36000 PLEASE WAIT\n",
      "EVALUATING ROW 36300 PLEASE WAIT\n",
      "EVALUATING ROW 36600 PLEASE WAIT\n",
      "EVALUATING ROW 36900 PLEASE WAIT\n",
      "EVALUATING ROW 37200 PLEASE WAIT\n",
      "EVALUATING ROW 37500 PLEASE WAIT\n",
      "EVALUATING ROW 37800 PLEASE WAIT\n",
      "EVALUATING ROW 38100 PLEASE WAIT\n",
      "EVALUATING ROW 38400 PLEASE WAIT\n",
      "EVALUATING ROW 38700 PLEASE WAIT\n",
      "EVALUATING ROW 39000 PLEASE WAIT\n",
      "EVALUATING ROW 39300 PLEASE WAIT\n",
      "EVALUATING ROW 39600 PLEASE WAIT\n",
      "EVALUATING ROW 39900 PLEASE WAIT\n",
      "EVALUATING ROW 40200 PLEASE WAIT\n",
      "EVALUATING ROW 40500 PLEASE WAIT\n",
      "EVALUATING ROW 40800 PLEASE WAIT\n",
      "EVALUATING ROW 41100 PLEASE WAIT\n",
      "EVALUATING ROW 41400 PLEASE WAIT\n",
      "EVALUATING ROW 41700 PLEASE WAIT\n",
      "EVALUATING ROW 42000 PLEASE WAIT\n",
      "EVALUATING ROW 42300 PLEASE WAIT\n",
      "EVALUATING ROW 42600 PLEASE WAIT\n",
      "EVALUATING ROW 42900 PLEASE WAIT\n",
      "EVALUATING ROW 43200 PLEASE WAIT\n",
      "EVALUATING ROW 43500 PLEASE WAIT\n",
      "EVALUATING ROW 43800 PLEASE WAIT\n",
      "EVALUATING ROW 44100 PLEASE WAIT\n",
      "EVALUATING ROW 44400 PLEASE WAIT\n",
      "EVALUATING ROW 44700 PLEASE WAIT\n",
      "EVALUATING ROW 45000 PLEASE WAIT\n",
      "EVALUATING ROW 45300 PLEASE WAIT\n",
      "EVALUATING ROW 45600 PLEASE WAIT\n",
      "EVALUATING ROW 45900 PLEASE WAIT\n",
      "EVALUATING ROW 46200 PLEASE WAIT\n",
      "EVALUATING ROW 46500 PLEASE WAIT\n",
      "EVALUATING ROW 46800 PLEASE WAIT\n",
      "EVALUATING ROW 47100 PLEASE WAIT\n",
      "EVALUATING ROW 47400 PLEASE WAIT\n",
      "EVALUATING ROW 47700 PLEASE WAIT\n",
      "EVALUATING ROW 48000 PLEASE WAIT\n",
      "EVALUATING ROW 48300 PLEASE WAIT\n",
      "EVALUATING ROW 48600 PLEASE WAIT\n",
      "EVALUATING ROW 48900 PLEASE WAIT\n",
      "EVALUATING ROW 49200 PLEASE WAIT\n",
      "EVALUATING ROW 49500 PLEASE WAIT\n",
      "EVALUATING ROW 49800 PLEASE WAIT\n",
      "EVALUATING ROW 50100 PLEASE WAIT\n",
      "EVALUATING ROW 50400 PLEASE WAIT\n",
      "EVALUATING ROW 50700 PLEASE WAIT\n",
      "EVALUATING ROW 51000 PLEASE WAIT\n",
      "EVALUATING ROW 51300 PLEASE WAIT\n",
      "EVALUATING ROW 51600 PLEASE WAIT\n",
      "EVALUATING ROW 51900 PLEASE WAIT\n",
      "EVALUATING ROW 52200 PLEASE WAIT\n",
      "EVALUATING ROW 52500 PLEASE WAIT\n",
      "EVALUATING ROW 52800 PLEASE WAIT\n",
      "EVALUATING ROW 53100 PLEASE WAIT\n",
      "EVALUATING ROW 53400 PLEASE WAIT\n",
      "EVALUATING ROW 53700 PLEASE WAIT\n",
      "EVALUATING ROW 54000 PLEASE WAIT\n",
      "EVALUATING ROW 54300 PLEASE WAIT\n",
      "EVALUATING ROW 54600 PLEASE WAIT\n",
      "EVALUATING ROW 54900 PLEASE WAIT\n",
      "EVALUATING ROW 55200 PLEASE WAIT\n",
      "EVALUATING ROW 55500 PLEASE WAIT\n",
      "EVALUATING ROW 55800 PLEASE WAIT\n",
      "EVALUATING ROW 56100 PLEASE WAIT\n",
      "EVALUATING ROW 56400 PLEASE WAIT\n",
      "EVALUATING ROW 56700 PLEASE WAIT\n",
      "EVALUATING ROW 57000 PLEASE WAIT\n",
      "EVALUATING ROW 57300 PLEASE WAIT\n",
      "EVALUATING ROW 57600 PLEASE WAIT\n",
      "EVALUATING ROW 57900 PLEASE WAIT\n",
      "EVALUATING ROW 58200 PLEASE WAIT\n",
      "EVALUATING ROW 58500 PLEASE WAIT\n",
      "EVALUATING ROW 58800 PLEASE WAIT\n",
      "EVALUATING ROW 59100 PLEASE WAIT\n",
      "EVALUATING ROW 59400 PLEASE WAIT\n",
      "EVALUATING ROW 59700 PLEASE WAIT\n",
      "EVALUATING ROW 60000 PLEASE WAIT\n",
      "EVALUATING ROW 60300 PLEASE WAIT\n",
      "EVALUATING ROW 60600 PLEASE WAIT\n",
      "EVALUATING ROW 60900 PLEASE WAIT\n",
      "EVALUATING ROW 61200 PLEASE WAIT\n",
      "EVALUATING ROW 61500 PLEASE WAIT\n",
      "EVALUATING ROW 61800 PLEASE WAIT\n",
      "EVALUATING ROW 62100 PLEASE WAIT\n",
      "EVALUATING ROW 62400 PLEASE WAIT\n",
      "EVALUATING ROW 62700 PLEASE WAIT\n",
      "EVALUATING ROW 63000 PLEASE WAIT\n",
      "EVALUATING ROW 63300 PLEASE WAIT\n",
      "EVALUATING ROW 63600 PLEASE WAIT\n",
      "EVALUATING ROW 63900 PLEASE WAIT\n",
      "EVALUATING ROW 64200 PLEASE WAIT\n",
      "EVALUATING ROW 64500 PLEASE WAIT\n"
     ]
    }
   ],
   "source": [
    "signal = np.zeros((eeg1_data.shape[1],2))\n",
    "signal[:,0] = eeg1_data[0,:].reshape(eeg1_data.shape[1])\n",
    "signal[:,1] = eeg2_data[0,:].reshape(eeg2_data.shape[1])\n",
    "vals = power_features(signal=signal, sampling_rate=128,bands=bands, custom = True)\n",
    "f = eeg_features(vals)\n",
    "features = np.zeros((eeg1_data.shape[0],f.shape[1]))\n",
    "\n",
    "for i in range(eeg1_data.shape[0]):\n",
    "    if i%300==0:\n",
    "        print(\"EVALUATING ROW {} PLEASE WAIT\".format(i))\n",
    "    signal = np.zeros((eeg1_data.shape[1],2))\n",
    "    signal[:,0] = eeg1_data[i,:].reshape(eeg1_data.shape[1])\n",
    "    signal[:,1] = eeg2_data[i,:].reshape(eeg2_data.shape[1])\n",
    "    vals = power_features(signal=signal, sampling_rate=128,bands=bands, custom = True)\n",
    "    features[i,:] = eeg_features(vals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING ROW 0 PLEASE WAIT\n",
      "EVALUATING ROW 300 PLEASE WAIT\n",
      "EVALUATING ROW 600 PLEASE WAIT\n",
      "EVALUATING ROW 900 PLEASE WAIT\n",
      "EVALUATING ROW 1200 PLEASE WAIT\n",
      "EVALUATING ROW 1500 PLEASE WAIT\n",
      "EVALUATING ROW 1800 PLEASE WAIT\n",
      "EVALUATING ROW 2100 PLEASE WAIT\n",
      "EVALUATING ROW 2400 PLEASE WAIT\n",
      "EVALUATING ROW 2700 PLEASE WAIT\n",
      "EVALUATING ROW 3000 PLEASE WAIT\n",
      "EVALUATING ROW 3300 PLEASE WAIT\n",
      "EVALUATING ROW 3600 PLEASE WAIT\n",
      "EVALUATING ROW 3900 PLEASE WAIT\n",
      "EVALUATING ROW 4200 PLEASE WAIT\n",
      "EVALUATING ROW 4500 PLEASE WAIT\n",
      "EVALUATING ROW 4800 PLEASE WAIT\n",
      "EVALUATING ROW 5100 PLEASE WAIT\n",
      "EVALUATING ROW 5400 PLEASE WAIT\n",
      "EVALUATING ROW 5700 PLEASE WAIT\n",
      "EVALUATING ROW 6000 PLEASE WAIT\n",
      "EVALUATING ROW 6300 PLEASE WAIT\n",
      "EVALUATING ROW 6600 PLEASE WAIT\n",
      "EVALUATING ROW 6900 PLEASE WAIT\n",
      "EVALUATING ROW 7200 PLEASE WAIT\n",
      "EVALUATING ROW 7500 PLEASE WAIT\n",
      "EVALUATING ROW 7800 PLEASE WAIT\n",
      "EVALUATING ROW 8100 PLEASE WAIT\n",
      "EVALUATING ROW 8400 PLEASE WAIT\n",
      "EVALUATING ROW 8700 PLEASE WAIT\n",
      "EVALUATING ROW 9000 PLEASE WAIT\n",
      "EVALUATING ROW 9300 PLEASE WAIT\n",
      "EVALUATING ROW 9600 PLEASE WAIT\n",
      "EVALUATING ROW 9900 PLEASE WAIT\n",
      "EVALUATING ROW 10200 PLEASE WAIT\n",
      "EVALUATING ROW 10500 PLEASE WAIT\n",
      "EVALUATING ROW 10800 PLEASE WAIT\n",
      "EVALUATING ROW 11100 PLEASE WAIT\n",
      "EVALUATING ROW 11400 PLEASE WAIT\n",
      "EVALUATING ROW 11700 PLEASE WAIT\n",
      "EVALUATING ROW 12000 PLEASE WAIT\n",
      "EVALUATING ROW 12300 PLEASE WAIT\n",
      "EVALUATING ROW 12600 PLEASE WAIT\n",
      "EVALUATING ROW 12900 PLEASE WAIT\n",
      "EVALUATING ROW 13200 PLEASE WAIT\n",
      "EVALUATING ROW 13500 PLEASE WAIT\n",
      "EVALUATING ROW 13800 PLEASE WAIT\n",
      "EVALUATING ROW 14100 PLEASE WAIT\n",
      "EVALUATING ROW 14400 PLEASE WAIT\n",
      "EVALUATING ROW 14700 PLEASE WAIT\n",
      "EVALUATING ROW 15000 PLEASE WAIT\n",
      "EVALUATING ROW 15300 PLEASE WAIT\n",
      "EVALUATING ROW 15600 PLEASE WAIT\n",
      "EVALUATING ROW 15900 PLEASE WAIT\n",
      "EVALUATING ROW 16200 PLEASE WAIT\n",
      "EVALUATING ROW 16500 PLEASE WAIT\n",
      "EVALUATING ROW 16800 PLEASE WAIT\n",
      "EVALUATING ROW 17100 PLEASE WAIT\n",
      "EVALUATING ROW 17400 PLEASE WAIT\n",
      "EVALUATING ROW 17700 PLEASE WAIT\n",
      "EVALUATING ROW 18000 PLEASE WAIT\n",
      "EVALUATING ROW 18300 PLEASE WAIT\n",
      "EVALUATING ROW 18600 PLEASE WAIT\n",
      "EVALUATING ROW 18900 PLEASE WAIT\n",
      "EVALUATING ROW 19200 PLEASE WAIT\n",
      "EVALUATING ROW 19500 PLEASE WAIT\n",
      "EVALUATING ROW 19800 PLEASE WAIT\n",
      "EVALUATING ROW 20100 PLEASE WAIT\n",
      "EVALUATING ROW 20400 PLEASE WAIT\n",
      "EVALUATING ROW 20700 PLEASE WAIT\n",
      "EVALUATING ROW 21000 PLEASE WAIT\n",
      "EVALUATING ROW 21300 PLEASE WAIT\n",
      "EVALUATING ROW 21600 PLEASE WAIT\n",
      "EVALUATING ROW 21900 PLEASE WAIT\n",
      "EVALUATING ROW 22200 PLEASE WAIT\n",
      "EVALUATING ROW 22500 PLEASE WAIT\n",
      "EVALUATING ROW 22800 PLEASE WAIT\n",
      "EVALUATING ROW 23100 PLEASE WAIT\n",
      "EVALUATING ROW 23400 PLEASE WAIT\n",
      "EVALUATING ROW 23700 PLEASE WAIT\n",
      "EVALUATING ROW 24000 PLEASE WAIT\n",
      "EVALUATING ROW 24300 PLEASE WAIT\n",
      "EVALUATING ROW 24600 PLEASE WAIT\n",
      "EVALUATING ROW 24900 PLEASE WAIT\n",
      "EVALUATING ROW 25200 PLEASE WAIT\n",
      "EVALUATING ROW 25500 PLEASE WAIT\n",
      "EVALUATING ROW 25800 PLEASE WAIT\n",
      "EVALUATING ROW 26100 PLEASE WAIT\n",
      "EVALUATING ROW 26400 PLEASE WAIT\n",
      "EVALUATING ROW 26700 PLEASE WAIT\n",
      "EVALUATING ROW 27000 PLEASE WAIT\n",
      "EVALUATING ROW 27300 PLEASE WAIT\n",
      "EVALUATING ROW 27600 PLEASE WAIT\n",
      "EVALUATING ROW 27900 PLEASE WAIT\n",
      "EVALUATING ROW 28200 PLEASE WAIT\n",
      "EVALUATING ROW 28500 PLEASE WAIT\n",
      "EVALUATING ROW 28800 PLEASE WAIT\n",
      "EVALUATING ROW 29100 PLEASE WAIT\n",
      "EVALUATING ROW 29400 PLEASE WAIT\n",
      "EVALUATING ROW 29700 PLEASE WAIT\n",
      "EVALUATING ROW 30000 PLEASE WAIT\n",
      "EVALUATING ROW 30300 PLEASE WAIT\n",
      "EVALUATING ROW 30600 PLEASE WAIT\n",
      "EVALUATING ROW 30900 PLEASE WAIT\n",
      "EVALUATING ROW 31200 PLEASE WAIT\n",
      "EVALUATING ROW 31500 PLEASE WAIT\n",
      "EVALUATING ROW 31800 PLEASE WAIT\n",
      "EVALUATING ROW 32100 PLEASE WAIT\n",
      "EVALUATING ROW 32400 PLEASE WAIT\n",
      "EVALUATING ROW 32700 PLEASE WAIT\n",
      "EVALUATING ROW 33000 PLEASE WAIT\n",
      "EVALUATING ROW 33300 PLEASE WAIT\n",
      "EVALUATING ROW 33600 PLEASE WAIT\n",
      "EVALUATING ROW 33900 PLEASE WAIT\n",
      "EVALUATING ROW 34200 PLEASE WAIT\n",
      "EVALUATING ROW 34500 PLEASE WAIT\n",
      "EVALUATING ROW 34800 PLEASE WAIT\n",
      "EVALUATING ROW 35100 PLEASE WAIT\n",
      "EVALUATING ROW 35400 PLEASE WAIT\n",
      "EVALUATING ROW 35700 PLEASE WAIT\n",
      "EVALUATING ROW 36000 PLEASE WAIT\n",
      "EVALUATING ROW 36300 PLEASE WAIT\n",
      "EVALUATING ROW 36600 PLEASE WAIT\n",
      "EVALUATING ROW 36900 PLEASE WAIT\n",
      "EVALUATING ROW 37200 PLEASE WAIT\n",
      "EVALUATING ROW 37500 PLEASE WAIT\n",
      "EVALUATING ROW 37800 PLEASE WAIT\n",
      "EVALUATING ROW 38100 PLEASE WAIT\n",
      "EVALUATING ROW 38400 PLEASE WAIT\n",
      "EVALUATING ROW 38700 PLEASE WAIT\n",
      "EVALUATING ROW 39000 PLEASE WAIT\n",
      "EVALUATING ROW 39300 PLEASE WAIT\n",
      "EVALUATING ROW 39600 PLEASE WAIT\n",
      "EVALUATING ROW 39900 PLEASE WAIT\n",
      "EVALUATING ROW 40200 PLEASE WAIT\n",
      "EVALUATING ROW 40500 PLEASE WAIT\n",
      "EVALUATING ROW 40800 PLEASE WAIT\n",
      "EVALUATING ROW 41100 PLEASE WAIT\n",
      "EVALUATING ROW 41400 PLEASE WAIT\n",
      "EVALUATING ROW 41700 PLEASE WAIT\n",
      "EVALUATING ROW 42000 PLEASE WAIT\n",
      "EVALUATING ROW 42300 PLEASE WAIT\n",
      "EVALUATING ROW 42600 PLEASE WAIT\n",
      "EVALUATING ROW 42900 PLEASE WAIT\n"
     ]
    }
   ],
   "source": [
    "signal = np.zeros((eeg1_test.shape[1],2))\n",
    "signal[:,0] = eeg1_test[0,:].reshape(eeg1_test.shape[1])\n",
    "signal[:,1] = eeg2_test[0,:].reshape(eeg2_test.shape[1])\n",
    "vals = power_features(signal=signal, sampling_rate=128,bands=bands, custom = True)\n",
    "f = eeg_features(vals)\n",
    "test_f = np.zeros((eeg1_test.shape[0],f.shape[1]))\n",
    "\n",
    "for i in range(eeg1_test.shape[0]):\n",
    "    if i%300==0:\n",
    "        print(\"EVALUATING ROW {} PLEASE WAIT\".format(i))\n",
    "    signal = np.zeros((eeg1_data.shape[1],2))\n",
    "    signal[:,0] = eeg1_test[i,:].reshape(eeg1_test.shape[1])\n",
    "    signal[:,1] = eeg2_test[i,:].reshape(eeg2_test.shape[1])\n",
    "    vals = power_features(signal=signal, sampling_rate=128,bands=bands, custom = True)\n",
    "    test_f[i,:] = eeg_features(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"extracted_features_test.csv\",test_f,delimiter=\",\")\n",
    "np.savetxt(\"extracted_features_train.csv\",features,delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.loadtxt(\"extracted_features_train.csv\",delimiter=\",\")\n",
    "test_f = np.loadtxt(\"extracted_features_test.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier((1024,1024),verbose=True,early_stopping=False,shuffle=False,max_iter=20)\n",
    "#nn.fit(features,labels)\n",
    "#nn.predict(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=500)\n",
    "pca.fit(features)\n",
    "features = pca.transform(features)\n",
    "test_f = pca.transform(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64800, 500)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FITTING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pouya/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.88467009\n",
      "Iteration 2, loss = 0.71847203\n",
      "Iteration 3, loss = 0.81555472\n",
      "Iteration 4, loss = 0.65929885\n",
      "Iteration 5, loss = 0.63653220\n",
      "Iteration 6, loss = 0.64362203\n",
      "Iteration 7, loss = 0.67614475\n",
      "Iteration 8, loss = 0.64597561\n",
      "Iteration 9, loss = 0.63795999\n",
      "Iteration 10, loss = 0.63712585\n",
      "Iteration 11, loss = 0.61805410\n",
      "Iteration 12, loss = 0.59548167\n",
      "Iteration 13, loss = 0.63736696\n",
      "Iteration 14, loss = 0.60413202\n",
      "Iteration 15, loss = 0.61294541\n",
      "Iteration 16, loss = 0.60742780\n",
      "Iteration 17, loss = 0.59368451\n",
      "Iteration 18, loss = 0.60739391\n",
      "Iteration 19, loss = 0.65163722\n",
      "Iteration 20, loss = 0.60647933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pouya/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21600,)\n",
      "(21600,)\n",
      "0.5712538360619149\n",
      "FITTING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pouya/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/pouya/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6ab8c4fdf36d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleave_one_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-6ab8c4fdf36d>\u001b[0m in \u001b[0;36mleave_one_out\u001b[0;34m(data, labels, clf)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FITTING\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \"\"\"\n\u001b[1;32m    957\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coefs_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    678\u001b[0m                                          layer_units[i + 1])))\n\u001b[1;32m    679\u001b[0m         \u001b[0;31m# forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             activations[i + 1] = safe_sparse_dot(activations[i],\n\u001b[0;32m--> 101\u001b[0;31m                                                  self.coefs_[i])\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def leave_one_out(data, labels, clf):\n",
    "    x = np.split(data,3)\n",
    "    y = np.split(labels,3)\n",
    "    vals = []\n",
    "    for i in range(3):\n",
    "        \n",
    "        x_val = x[i]\n",
    "        y_val = labels[i*21600:(i+1)*21600]\n",
    "        \n",
    "    \n",
    "        x_train = np.zeros((x_val.shape[0]*2,x_val.shape[1]))\n",
    "        y_train = np.zeros((x_val.shape[0]*2,1))\n",
    "        x_train[:21600,:] = x[(i+1)%3]\n",
    "        x_train[21600:,:] = x[(i+2)%3]\n",
    "        y_train[:21600] = y[(i+1)%3].reshape(x_val.shape[0],1)\n",
    "        y_train[21600:] = y[(i+2)%3].reshape(x_val.shape[0],1)\n",
    "        print(\"FITTING\")\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred = clf.predict(x_val)\n",
    "        print(y_pred.shape)\n",
    "        print(y_val.shape)\n",
    "        val = balanced_accuracy_score(y_val,y_pred)\n",
    "        print(val)\n",
    "        vals.append(val)\n",
    "    return vals\n",
    "\n",
    "vals = leave_one_out(features,labels,nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.fit(features,labels)\n",
    "pred = nn.predict(test_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"sample.csv\", delimiter=',')\n",
    "sample['y'] = pred\n",
    "sample.to_csv(\"NN_eegOnly.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
